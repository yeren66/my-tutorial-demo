# 阅读论文笔记

记录阅读论文时的摘要与思考。

## 示例笔记

- 📘 标题：《Attention is All You Need》
- 🧠 要点：提出了 Transformer 模型，取消 RNN，全面依赖注意力机制。
- 💬 评注：该模型极大提升了并行计算能力，是后续 GPT/BERT 的基础。

![20250524170457](https://isedocument.oss-cn-beijing.aliyuncs.com/images/20250524170457.png)

